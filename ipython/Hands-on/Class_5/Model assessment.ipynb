{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction to Data Science\n",
    "## Model assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the packages we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the libraries we will be using\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "\n",
    "model_types = [\"logistic_regression\", \"decision_tree\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "We're going to use a mail response data set from a real direct marketing campaign located in `data/mailing.csv`. Each record represents an individual who was targeted with a direct marketing offer.  The offer was a solicitation to make a charitable donation. \n",
    "\n",
    "The columns (features) are:\n",
    "\n",
    "```\n",
    "income       household income\n",
    "Firstdate    data assoc. with the first gift by this individual\n",
    "Lastdate     data associated with the most recent gift \n",
    "Amount       average amount by this individual over all periods (incl. zeros)\n",
    "rfaf2        frequency code\n",
    "rfaa2        donation amount code\n",
    "pepstrfl     flag indicating a star donator\n",
    "glast        amount of last gift\n",
    "gavr         amount of average gift\n",
    "```\n",
    "\n",
    "The target variables is `class` and is equal to one if they gave in this campaign and zero otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"data/mailing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take a look at the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the description above, and the head of the data, we see that two of the fields are **categorical** (text) instead of the typical **numerical** fields we have been looking at until this point. Today, one of the models we will be using is a logistic regression. From the previous classes, we have seen that logistic regression requires *all* fields to be numerical. To do this, we are going to create dummy variables for all the fields that are categorical.\n",
    "\n",
    "#### Dummyize\n",
    "The typical way to create dummys for a field is to create new variables for each possible category of the field. For example consider a field called color that can have the possible values \"red\", \"blue\", and \"green\". To dummyize color, we would create three new features: \"color_red\", \"color_blue\", and \"color_green\". These fields would take the value 1 or 0 depending on the actual value of color. Each record can only have one of these fields set to 1!\n",
    "\n",
    "As a small detail, you should leave out one of the possible categories. So, for example, in the above example that had three possible values, you should only create two dummies. The value you leave out doesn't matter, you can choose it at random.\n",
    "\n",
    "Let's dummyize the fields `rfaa2` and `pepstrfl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for field in ['rfaa2', 'pepstrfl']:\n",
    "    # Go through each possible value except the last one\n",
    "    for value in data[field].unique()[0:-1]:\n",
    "        # Create a new binary field\n",
    "        data[field + \"_\" + value] = pd.Series(data[field] == value, dtype=int)\n",
    "\n",
    "    # Drop the original field\n",
    "    data = data.drop([field], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's take another look at the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is now numeric! Let's wrap up by putting all of the *predictors* into `X` and the target variable into `Y`. We will also split our data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data.drop(['class'], axis=1)\n",
    "Y = data['class']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrices\n",
    "Let's build a confusion matrix using a logistic regression model with the default setting of predicting a 1 if the probability is $\\geq$ 50%.\n",
    "\n",
    "Remember, a confusion matrix looks like:\n",
    "\n",
    "```\n",
    "  |____________ p __________|___________ n ___________|\n",
    "Y | 1's predicted to be 1's | 0's predicted to be 1's |\n",
    "N | 1's predicted to be 0's | 0's predicted to be 0's |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make and fit a model on the training data\n",
    "model = LogisticRegression(C=1000000)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Get probabilities of being a 1\n",
    "probabilities = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the threshold of 0.5 to predict a 1\n",
    "prediction = probabilities > 0.5\n",
    "\n",
    "# Build and print a confusion matrix\n",
    "confusion_matrix_large = pd.DataFrame(metrics.confusion_matrix(Y_test, prediction, labels=[1, 0]).T,\n",
    "                                columns=['p', 'n'], index=['Y', 'N'])\n",
    "print confusion_matrix_large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we lower the threshold to 5%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's move the threshold down\n",
    "prediction = probabilities > 0.05\n",
    "\n",
    "# Build and print a confusion matrix\n",
    "confusion_matrix_small = pd.DataFrame(metrics.confusion_matrix(Y_test, prediction, labels=[1, 0]).T,\n",
    "                                columns=['p', 'n'], index=['Y', 'N'])\n",
    "print confusion_matrix_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this good performance? How can we tell. Let's computer the profit it would produce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit curves\n",
    "Let's say that our profit margin is small: each offer costs \\$1 to make and market, and each accepted offer earns \\$18, for a profit of $17. The cost matrix would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost_matrix = pd.DataFrame([[None, None], [None, None]], columns=['p', 'n'], index=['Y', 'N'])\n",
    "print cost_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected profit of using 50% and 5% as your prediction threshold would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Expected profit with a cutoff of 50%% is $%.2f.\" % np.sum(np.sum(confusion_matrix_large/float(len(Y_test)) * cost_matrix))\n",
    "print \"Expected profit with a cutoff of 5%% is $%.2f.\" % np.sum(np.sum(confusion_matrix_small/float(len(Y_test)) * cost_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try all possible thresholds, we can plot the profit curve. Note that here the total profit calculation implies some particular size of the population to which you would apply the model. Let's start by assuming that it is the same size as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the false positive rate, true positive rate, and all thresholds\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test, model.predict_proba(X_test)[:,1])\n",
    "Size_targeted_pop = float(len(Y_test))\n",
    "\n",
    "# What is the baseline probability of being positive or negative in the data set?\n",
    "p_p = np.sum(Y_test)/float(len(Y_test))\n",
    "p_n = 1 - np.sum(Y_test)/float(len(Y_test))\n",
    "\n",
    "# How many users are above the current threshold?\n",
    "n_targeted = []\n",
    "for t in thresholds:\n",
    "    n_targeted.append(np.sum(probabilities >= t))\n",
    "\n",
    "# Turn these counts to percentages of users above the threshold\n",
    "n_targeted = np.array(n_targeted)/float(len(Y_test))\n",
    "\n",
    "# Expected profits:  \n",
    "expected_profits = (cost_matrix['p']['Y']*(tpr*p_p)) + (cost_matrix['n']['Y']*(fpr*p_n))\n",
    "\n",
    "# Plot the profit curve\n",
    "plt.plot(n_targeted, Size_targeted_pop*expected_profits)\n",
    "plt.xlabel(\"Percentage of users targeted\")\n",
    "plt.ylabel(\"Profit\")\n",
    "plt.title(\"Profits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative response and lift curves\n",
    "What if we can't specify the costs and benefits? Let's take a look at a cumulative response curve for two different classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep track of all output\n",
    "xs = {}\n",
    "ys = {}\n",
    "\n",
    "for model_type in model_types:\n",
    "    # Instantiate the model\n",
    "    if model_type == \"decision_tree\":\n",
    "        model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=15)\n",
    "    elif model_type == \"logistic_regression\":\n",
    "        model = LogisticRegression(C=1000000)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Get the predicted value and the probability of Y_test records being = 1\n",
    "    Y_test_predicted = model.predict(X_test)\n",
    "    Y_test_probability_1 = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(Y_test, Y_test_probability_1)\n",
    "\n",
    "    # How many users are above the current threshold?\n",
    "    n_targeted = []\n",
    "    for t in thresholds:\n",
    "        n_targeted.append(np.sum(probabilities >= t))\n",
    "\n",
    "    # Turn these counts to percentages of users above the threshold\n",
    "    n_targeted = np.array(n_targeted)/float(len(Y_test))\n",
    "\n",
    "    # Store\n",
    "    xs[model_type] = n_targeted * 100\n",
    "    ys[model_type] = tpr * 100\n",
    "    \n",
    "    # Plot\n",
    "    plt.plot(n_targeted * 100, tpr * 100, label=model_type)# * np.sum(Y_test)/float(len(Y_test)))\n",
    "\n",
    "plt.plot([0,100], [0,100], 'k--', label=\"Random\")\n",
    "plt.xlabel(\"Percentage of test instances targeted (decreasing score)\")\n",
    "plt.ylabel(\"Percentage of positives targeted\")\n",
    "plt.title(\"Cumulative response curve\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily look at a lift curve in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_type in model_types:\n",
    "    x_lift = xs[model_type]\n",
    "    y_lift = ys[model_type]/x_lift\n",
    "\n",
    "    plt.plot(x_lift, y_lift, label=model_type)\n",
    "\n",
    "plt.plot([0,100], [1,1], 'k--', label=\"Random\")\n",
    "plt.xlabel(\"Percentage of test instances targeted (decreasing score)\")\n",
    "plt.ylabel(\"Percentage of positives targeted\")\n",
    "plt.title(\"Lift curve\")\n",
    "plt.xlim([0,100])\n",
    "plt.ylim([0,10])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver operating characteristic (ROC) curves\n",
    "For this data set, let's take a look at the ROC curves generated by our classifiers. This can be useful if you don't know the class distribution in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_type in model_types:\n",
    "    # Instantiate the model\n",
    "    if model_type == \"decision_tree\":\n",
    "        model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=15)\n",
    "    elif model_type == \"logistic_regression\":\n",
    "        model = LogisticRegression(C=1000000)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Get the probability of Y_test records being = 1\n",
    "    Y_test_probability_1 = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Use the metrics.roc_curve function to get the true positive rate (tpr) and false positive rate (fpr)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(Y_test, Y_test_probability_1)\n",
    "\n",
    "    # Get the area under the curve (AUC)\n",
    "    acc = np.mean(cross_validation.cross_val_score(model, X, Y, scoring=\"accuracy\"))\n",
    "    auc = np.mean(cross_validation.cross_val_score(model, X, Y, scoring=\"roc_auc\"))\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, label=model_type + \" (AUC = \" + str(round(auc, 2)) + \")\")\n",
    "plt.xlabel(\"False positive rate (fpr)\")\n",
    "plt.ylabel(\"True positive rate (tpr)\")\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"Random\")\n",
    "plt.legend(loc=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
