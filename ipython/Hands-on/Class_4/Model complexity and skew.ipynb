{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Model complexity and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we will start by importing some useful Python packages and creating some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the libraries we will be using\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# I've abstracted some of what we'll be doing today into a library.\n",
    "# You can take a look at this code if you want by going into `dstools/data_tools.py`\n",
    "from dstools import data_tools\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 14, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get some data\n",
    "target_name, variable_names, data, Y = data_tools.create_data()\n",
    "\n",
    "# Grab the predictors with sufficient complexity (3rd order interaction terms)\n",
    "X = data_tools.X(complexity=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization in logistic regression\n",
    "\n",
    "Last class we saw that when fitting a logistic regression classifier, we try to find the set of weights, $\\textbf{w}$, that maximize the fit function $g()$,\n",
    "\n",
    "$\\arg\\max_\\textbf{w} g(\\textbf{x}, \\textbf{w})$.\n",
    "\n",
    "We can penalize our model for getting too complex by adding a penalty function and using the weight $\\lambda$ to determine how much importance our optimization procedure should place on the penalty,\n",
    "\n",
    "$\\arg\\max_\\textbf{w} g(\\textbf{x}, \\textbf{w}) - \\lambda \\cdot \\text{penalty}(\\textbf{w})$.\n",
    "\n",
    "The two most common type of regularization are $L_1$ and $L_2$ regularization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot different regularization values for L1 and L2 regularization\n",
    "for regularization in ['L2', 'L1']:\n",
    "    # Get a table of the model coefficients\n",
    "    coefs = pd.DataFrame(columns=['C'] + list(X.columns))\n",
    "    \n",
    "    # Print what we are doing\n",
    "    print \"Fitting with %s regularization:\" % regularization\n",
    "    position = 0\n",
    "    \n",
    "    # Try some regularization values\n",
    "    for i in range(-6, 3):\n",
    "        # Modeling\n",
    "        c = np.power(10.0, i)\n",
    "        model = LogisticRegression(penalty=regularization.lower(), C=c)\n",
    "        model.fit(X, Y)\n",
    "        \n",
    "        # Plotting\n",
    "        position += 1\n",
    "        plt.subplot(3, 3, position)\n",
    "        data_tools.Decision_Surface(X, Y, model)\n",
    "        plt.title(\"C = \" + str(np.power(10.0, i)))\n",
    "        \n",
    "        # Update coefficient table\n",
    "        coefs.loc[i] = [c] + list(model.coef_[0])\n",
    "    # Print and plot\n",
    "    print coefs.to_string(index=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-on with your neighbors\n",
    "\n",
    "The following cell will create some data for you to explore. With your neighbors, try to build the best performing model you can. `X_handson` consists of three potential predictors: \"income\", \"residence\", and \"job\". Use any or all of these features to build the best model you can for predicting the target variable, purchasing insurance, given in `Y_handson`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create hands-on data\n",
    "from dstools import data_tools\n",
    "\n",
    "X_handson, Y_handson = data_tools.handson_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try it out!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
