{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Model assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the packages we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the libraries we will be using\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# I've abstracted some of what we'll be doing today into a library.\n",
    "# You can take a look at this code if you want by going into `dstools/data_tools.py`\n",
    "from dstools import data_tools\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get some data\n",
    "from dstools import data_tools\n",
    "\n",
    "X, Y = data_tools.handson_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver operating characteristic (ROC) curves\n",
    "Let's rebuild the type of model we looked at in the previous notebook's group portion. Here were are trying to predict if customers are given a credit card (`Y_handson = 1`) using the three features in `X_handson`: \"earning\", \"geographic\", and \"experience\".\n",
    "\n",
    "Up until this point we have been using Accuracy (the number of records correctly classified divided by the total number of records). However, we saw that this does not always give us the \"best\" interpretation of our model's performance. Another way to measure the performance of a model is to use reciever operating characteristic (ROC) curves. Doing this in sklearn is relatively straight forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by dividing our data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build and fit a model. Using this model, we will plot an ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit a logistic regression model\n",
    "for c in [0.001, 0.01, 0.1, 1.0]:\n",
    "    model = LogisticRegression(C=c)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Get the probability of Y_test records being = 1\n",
    "    Y_test_probability_1 = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Use the metrics.roc_curve function to get the true positive rate (tpr) and false positive rate (fpr)\n",
    "    tpr, fpr, thresholds = metrics.roc_curve(Y_test, Y_test_probability_1)\n",
    "\n",
    "    # Get the area under the curve (AUC)\n",
    "    acc = np.mean(cross_validation.cross_val_score(model, X, Y, scoring=\"accuracy\"))\n",
    "    auc = np.mean(cross_validation.cross_val_score(model, X, Y, scoring=\"roc_auc\"))\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(tpr, fpr, label=\"AUC (C=\" + str(c) + \") = \" + str(round(auc, 2)))\n",
    "plt.xlabel(\"True positive rate (tpr)\")\n",
    "plt.ylabel(\"False positive rate (fpr)\")\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"Random\")\n",
    "plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative response and lift curves\n",
    "The interpretation of an ROC curve may not be entirely intuitive. Let's look at cumulative response curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit a logistic regression model\n",
    "model = LogisticRegression(C=1.0)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Get the predicted value and the probability of Y_test records being = 1\n",
    "Y_test_predicted = model.predict(X_test)\n",
    "Y_test_probability_1 = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Sort these predictions, probabilities, and the true value in descending order of probability\n",
    "order = np.argsort(Y_test_probability_1)[::-1]\n",
    "Y_test_predicted_sorted = Y_test_predicted[order]\n",
    "Y_test_probability_1_sorted = Y_test_probability_1[order]\n",
    "Y_test_sorted = np.array(Y_test)[order]\n",
    "\n",
    "# Go record-by-record and build the cumulative response curve\n",
    "x_cumulative = []\n",
    "y_cumulative = []\n",
    "total_test_positives = np.sum(Y_test)\n",
    "for i in range(1, len(Y_test_probability_1_sorted)+1):\n",
    "    x_cumulative.append(i)\n",
    "    y_cumulative.append(np.sum(Y_test_sorted[0:i]) / float(total_test_positives))\n",
    "\n",
    "# Rescale\n",
    "x_cumulative = np.array(x_cumulative)/float(np.max(x_cumulative)) * 100\n",
    "y_cumulative = np.array(y_cumulative) * 100\n",
    "\n",
    "# Plot\n",
    "plt.plot(x_cumulative, y_cumulative, label=\"Classifier\")\n",
    "plt.plot([0,100], [0,100], 'k--', label=\"Random\")\n",
    "plt.xlabel(\"Percentage of test instances (decreasing score)\")\n",
    "plt.ylabel(\"Percentage of positives targeted\")\n",
    "plt.title(\"Cumulative response curve\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily look at a lift curve in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_lift = x_cumulative\n",
    "y_lift = y_cumulative/x_lift\n",
    "\n",
    "plt.plot(x_lift, y_lift, label=\"Classifier\")\n",
    "plt.plot([0,100], [1,1], 'k--', label=\"Random\")\n",
    "plt.xlabel(\"Percentage of test instances (decreasing score)\")\n",
    "plt.ylabel(\"Percentage of positives targeted\")\n",
    "plt.title(\"Lift curve\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
